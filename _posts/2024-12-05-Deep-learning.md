---
title: "From deep learning to Bayesian neural network: 1 - Deep learning and its theoretical framework"
date: 2024-12-05
---

## Deep learning and its theoretical framework
Deep learning is a hot research field these years and many architectures and training algorithms are proposed. Let us begin with a simplest case - a stochastic gradient descent (SGD) algorithm trained fully connected neural network (NN) for supervised learning task. 

A feed-forward NN consisting of \(L\) layers, each defined by weight matrices \(W^1,...,W^L\) and post-activation vectors \(x^1,...,x^L\), with \(N_l\) neurons per layer. Then the network 

## References